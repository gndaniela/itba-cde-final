# ITBA ML Applications

## <ins>Caso de uso:

Generar un modelo predictivo que con informaci√≥n hist√≥rica de partidos internacionales entre los distintos pa√≠ses, pueda determinar qui√©n es el ganador de enfrentamientos entre equipos participantes de la Copa del Mundo 2022.

## <ins>Identificaci√≥n del dataset:

Se utilizar√° como base para el an√°lisis un dataset disponible en [Kaggle](https://www.kaggle.com/datasets/brenda89/fifa-world-cup-2022), con informaci√≥n desde el a√±o 1993.

## <ins>Diagrama de arquitectura:

![Architecture](./documentation/img-narch.png)

## <ins>Implementaci√≥n:

* üèÉüèª‚Äç‚ôÇÔ∏è _Airflow - orquestador del proceso_: 

Funciona montado dentro de Docker, en una instancia de EC2.

El DAG creado se encarga de:

    * Generar los buckets de S3 que ser√°n utilizados por el proceso de punta a punta

    * Cargar los datos y scrips necesarios en cada bucket (.csv descargado de Kaggle, scripts que usar√° posteriormente EMR, archivo de bootstrap actions para instalar las librer√≠as correspondientes en el cluster en su creaci√≥n)       

    * Crear un cluster de EMR que utilizar√° Spark como motor de procesamiento, e  instancias spot para reducir costos

    * Generar los pasos que el cluster de EMR ejecutar√°:
        - Tomar el .csv crudo de Kaggle y convertirlo a parquet para aumentar la eficiencia
        - Correr un modelo de machine learning (RandomForestClassifier) que logre predecir si un equipo ganar√° o no, en un enfrentamiento puntual contra otro equipo
        - Guardar el modelo generado en un bucket de S3

    * Terminar el cluster una vez que todos los procesos se encuentren terminados

![DAG](./documentation/airflow-dag.png)

* üèÉüèª‚Äç‚ôÇÔ∏è _App - endpoint hacia los usuario finales_:
    
        * Flask ser√° utilizado como framework:
            - Recibe el input seleccionado por el usuario, se conecta a S3, toma el modelo predictivo guardado por el cluster de EMR y devuelve tanto el ganador del partido, como tambi√©n la probabilidad de que ocurra.

        * Nginx es utilizado como servidor y reverse proxy para canalizar los requests, y Gunicorn como servidor WSGI.        

    üèÜ App preview:

![Home page](./documentation/app-home.png)

![Prediction](./documentation/app-predict.png)

## <ins>Componentes:

### ‚öΩ VPC:

VPC creada en la regi√≥n US East - N. Virginia.
Est√° desplegada en dos AZs (us-east-1a, us-east-1b), cada una con la siguiente configuraci√≥n:

* Subnets:
    - 1 subnet privada
    - 1 subnet p√∫blica
    - 1 NAT Gateway en la subnet p√∫blica

* Internet Gateway

* Route tables
    - Subnets privadas:

    ![Private route table](./documentation/route-nat.png)

    - Subnets p√∫blicas:

    ![Public route table](./documentation/route-igw.png)


### ‚öΩ S3 - Buckets:

Buckets como fuente y destino de archivos est√°ticos:

   ![Public route table](./documentation/buckets.png)


### ‚öΩ Lambda:

Funci√≥n que tiene como trigger la llegada de archivos nuevos al bucket de datos iniciales sobre los partidos internacionales (itba-tp-raw-csv):

![Public route table](./documentation/lambda-trigger-s3.png)

Cuando este evento sucede, env√≠a un request a la [API de Airflow](https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html), y activa el DAG que corre todo el ETL + generaci√≥n del modelo de ML.

![Public route table](./documentation/lambda-result.png)

Se conecta a las subnets privadas de la VPC, y se comunica via NAT gateway con la instancia EC2 de Airflow.

### ‚öΩ EC2:

Es el servidor que funciona como host del docker que contiene a Airflow, y de la app en Flask.

Security group - inbound rules:

| **PORT** | **SOURCE** | **TYPE**    |
|----------|------------|-------------|
| 22       | 0.0.0.0/0  | SSH         |
| 80       | elb-sg     | HTTP        |
| 8080     | 0.0.0.0/0  | AIRFLOW     |
| 5000     | 0.0.0.0/0  | FLASK       |
| TCP-All  | lambda-sg  | LAMBDA CALL |


### ‚öΩ EMR:

Cluster generado para ejecutar jobs en Spark.
Convierte archivos planos .csv a parquet, y genera el modelo de ML.

![EMR](./documentation/emr-cluster-steps.png)

### ‚öΩ Application Load Balancer:

Generado para distribuir los requests hacia la app.

Inbound rules en security group:

- 80 (HTTP)

- 43 (HTTPS)

### ‚öΩ Auto Scaling group:

Asegura una alta disponiblidad, generando o eliminando instancias, seg√∫n el flujo de carga de la app. 
Se gener√≥ una AMI customizada con todos los requisitos para implementar la app. Dicha AMI se toma como launch configuration para los nuevos servidores.


### ‚öΩ RDS:

Registra todas las predicciones consultadas en la app, y el timestamp de su creaci√≥n.
De esta manera se podr√≠a generar un dashboard en Quicksight analizando, por ejemplo, cu√°les son los pa√≠ses m√°s consultados y los d√≠as y horas con mayor tr√°fico de la aplicaci√≥n.

Inbound rules en security group:

- 3396 (MySQL/Aurora) - Source: EC2 security group

![EMR](./documentation/db-table.png)

# Instalaci√≥n e implementaci√≥n

1. Utilizando CloudFormation (opci√≥n sugerida): 

En el archivo  `cfn_implementation_guide.md` se encuentran las instrucciones para dejar operativo el proyecto.

2. Sin CloudFormation:

En el archivo  `implementation_guide.md` se encuentran las instrucciones para dejar operativo el proyecto.

* Lineamientos generales:

En primer lugar deber√≠a crearse un servidor de EC2, en donde se clonar√° este git repo, y se realizar√°n las instalaciones y configuraciones correspondientes tanto para correr el servidor de Airflow como la app de Flask.

El repo contiene:

- `create_and_load_buckets.py` da inicio al proceso creando los buckets necesarios (si es que todav√≠a no existen), y cargando files en ellos
- `emr-dag.py` como dag principal y orquestador del proceso
- Files que utilizar√° EMR: 
    - `bootstrap_script.sh` configuraci√≥n inicial del cluster e instalador de las librer√≠as requeridas
    - `convert_csv_to_parquet.py` source para uno de los procesos que correr√°n para transformar archivos crudos de Kaggle a los parquets necesarios para correr el modelo de ML
    - `model_script.py` ejecutar el modelo clasificador RandomForestClassification
- `src/app` directorio root de la aplicaci√≥n de Flask, con todos sus ejecutables:
    - `app.py`: c√≥digo fuente de la app
    - `dbconnect.py`: funciones helper para conectarse a la RDS

# Mejoras

### ü•á CloudFront:
Cachear el contenido de la app y reducir la latencia en las respuestas

### ü•á Route 53:
Generar un DNS

### ü•á WAF:
Implementar un firewall para la app

### ü•á ECR:

Crear una imagen de nuestro docker-compose y utilizarlo desde ese servicio 

## __App demo video:__ 

[![App demo video](./documentation/app-ytb.png)](https://youtu.be/L9wwdtwOik0)
